{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raulespz/emotion_ai/blob/main/Emotion_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoFfteqZ6PSZ"
      },
      "outputs": [],
      "source": [
        "# Import the necessary packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from PIL import *\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.python.keras import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5wEDF6w7LnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "3f75673c-a076-44f8-be68-65feb5df69cc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1a71591daeae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeyfacial_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeyfacial_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data.csv'"
          ]
        }
      ],
      "source": [
        "keyfacial_df = pd.read_csv('/content/data.csv')\n",
        "keyfacial_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxGqUN9C81cC"
      },
      "outputs": [],
      "source": [
        "keyfacial_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFkB5XAdQXMu"
      },
      "outputs": [],
      "source": [
        "keyfacial_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9REFi5Rd8-JY"
      },
      "outputs": [],
      "source": [
        "keyfacial_df['Image'].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyfacial_df['Image'] = keyfacial_df['Image'].apply(lambda x: np.fromstring(x, dtype = int, sep = ' ').reshape(96, 96))"
      ],
      "metadata": {
        "id": "2Aj8Uj20bf_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyfacial_df['Image'][0].shape"
      ],
      "metadata": {
        "id": "wBW5qCjKbjMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyfacial_df.describe()"
      ],
      "metadata": {
        "id": "PQxJULowbybd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_EMCTXH9ItQ"
      },
      "outputs": [],
      "source": [
        "# keyfacial_df['Image'] = keyfacial_df['Image'].apply(lambda x: np.fromstring(x, dtype = int, sep = ' ').reshape(96, 96))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-RepzUmA88J"
      },
      "outputs": [],
      "source": [
        "#This one is in replace in the code of the upper cell due do not run:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'keyfacial_df' is your DataFrame with the 'Image' column\n",
        "\n",
        "# Define a function to handle the reshaping and handle the ValueError\n",
        "def reshape_image(x):\n",
        "    try:\n",
        "        return np.fromstring(x, dtype=int, sep=' ').reshape(96, 96)\n",
        "    except ValueError:\n",
        "        # Handle the error here (e.g., return a default value, raise an exception, etc.)\n",
        "        return np.zeros((96, 96))  # Default value as zeros\n",
        "\n",
        "# Apply the reshaping function to the 'Image' column\n",
        "keyfacial_df['Image'] = keyfacial_df['Image'].apply(reshape_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu9Yq5ExCyJP"
      },
      "outputs": [],
      "source": [
        "keyfacial_df['Image'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tROCFj6SCyAp"
      },
      "outputs": [],
      "source": [
        "i = np.random.randint(1, len(keyfacial_df)) # i code generates a random integer i between 1 and the length of the DataFrame keyfacial_df.\n",
        "plt.imshow(keyfacial_df['Image'][i], cmap = 'gray')\n",
        "for j in range(1, 31, 2):\n",
        "       plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n",
        "\n",
        "#for j in range(1, 31, 2): is a loop that iterates over a range of numbers.\n",
        "#In this case, it starts from 1, ends at 31 (exclusive), and increments by 2\n",
        "#in each iteration. So, j will take values 1, 3, 5, ..., 29.\n",
        "\n",
        "#keyfacial_df.loc[i][j-1] accesses the value at the index i\n",
        " #(which was randomly generated earlier) and column j-1 of the DataFrame\n",
        "# keyfacial_df. This code snippet selects a specific element from the\n",
        "# DataFrame based on the generated index i and the current value of j.\n",
        "\n",
        "#keyfacial_df.loc[i][j] accesses the value at the index i and column\n",
        "#j of the DataFrame keyfacial_df. Similar to the previous step, this\n",
        "#code snippet selects another specific element from the DataFrame.\n",
        "\n",
        "#plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n",
        "#creates a scatter plot using matplotlib's plot function. It plots\n",
        "#a single point with coordinates (keyfacial_df.loc[i][j-1],\n",
        "#                                 keyfacial_df.loc[i][j]) and uses a red 'x'\n",
        "#                                 marker ('rx') to represent the point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWmfftVfbvpa"
      },
      "outputs": [],
      "source": [
        "# Let's view more images in a grid format\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i in range(64):\n",
        "  ax = fig.add_subplot(8, 8, i + 1)\n",
        "  image = plt.imshow(keyfacial_df['Image'][i], cmap = 'gray')\n",
        "  for j in range(1, 31, 2):\n",
        "       plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# Let's view more images in a grid format\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i in range(64):\n",
        "    k = random.randint(1, len(keyfacial_df))\n",
        "    ax = fig.add_subplot(8, 8, i + 1)\n",
        "    image = plt.imshow(keyfacial_df['Image'][k],cmap = 'gray')\n",
        "    for j in range(1,31,2):\n",
        "        plt.plot(keyfacial_df.loc[k][j-1], keyfacial_df.loc[k][j], 'rx')"
      ],
      "metadata": {
        "id": "dQhj4gHVcX9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw0EIuykbvj6"
      },
      "outputs": [],
      "source": [
        "#Create a new copy of the dataframe\n",
        "\n",
        "import copy\n",
        "keyfacial_df_copy = copy.copy(keyfacial_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN7u0MZibvff"
      },
      "outputs": [],
      "source": [
        "#Obtain the columns in the dataframe\n",
        "columns = keyfacial_df_copy.columns[:-1] # this takes of the columns of our dataframe but not the last one\n",
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pnsus38bvbb"
      },
      "outputs": [],
      "source": [
        "#Horizontal Flip - flip the images along y axis\n",
        "\n",
        "#In simple terms, this line of code horizontally flips each image in the 'Image'\n",
        "#column of the DataFrame keyfacial_df_copy. It applies the np.flip() function from\n",
        "#NumPy to reverse the order of the elements along the horizontal axis (columns)\n",
        "#of each image, effectively flipping the image horizontally.\n",
        "#The modified images are then stored back in the 'Image' column of the DataFrame.\n",
        "\n",
        "keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x: np.flip(x, axis = 1))\n",
        "\n",
        "# since we are flipping horizontally, y coordinate values would be the same\n",
        "# Only x coordiante values would change, all we have to do is to subtract our initial x-coordinate values from width of the image(96)\n",
        "for i in range(len(columns)):\n",
        "  if i%2 == 0:\n",
        "    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmYCuq-rbvWa"
      },
      "outputs": [],
      "source": [
        "#Since we are flipping horizontally, y coordinate values would be the same\n",
        "#Only x coordinate values would change, all we have to do is to substract our initial x-coordinate values from width of the\n",
        "###for i in range(len(columns)):\n",
        "###  if i%2 == 0:\n",
        "###    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi3-l_32bvQ0"
      },
      "outputs": [],
      "source": [
        "# Show the original image\n",
        "plt.imshow(keyfacial_df['Image'][9], cmap = 'gray')\n",
        "for j in range(1, 31, 2):\n",
        "       plt.plot(keyfacial_df.loc[9][j-1], keyfacial_df.loc[9][j], 'rx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-ELgfohFZpu"
      },
      "outputs": [],
      "source": [
        "# Show the Horizontally flipped image\n",
        "plt.imshow(keyfacial_df_copy['Image'][9], cmap = 'gray')\n",
        "for j in range(1, 31, 2):\n",
        "       plt.plot(keyfacial_df.loc[9][j-1], keyfacial_df.loc[9][j], 'rx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LuGdEO5G0Ud"
      },
      "outputs": [],
      "source": [
        "# Concatenate the original dataframe with the augmented dataframe it means that we are going to duplicate our dataframe\n",
        "# with teh original dataframe and the copy that we already created to this augmented instance.\n",
        "augmented_df = np.concatenate((keyfacial_df, keyfacial_df_copy))\n",
        "augmented_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pChioyQUHrNq"
      },
      "outputs": [],
      "source": [
        "# Randomingly increasing the brightness of the images\n",
        "# We multiply pixel vlaues by random valkues between 1.5 and 2 to increase the brightness of the image\n",
        "# We clip the value between 0 to 255\n",
        "\n",
        "import random\n",
        "\n",
        "keyfacial_df_copy = copy.copy(keyfacial_df)\n",
        "keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x:np.clip(random.uniform(1.5, 2)* x, 0.0, 255.0))\n",
        "augmented_df = np.concatenate((augmented_df, keyfacial_df_copy))\n",
        "augmented_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Exrzxo-tKALn"
      },
      "outputs": [],
      "source": [
        "# Show Image with increased brightness\n",
        "plt.imshow(keyfacial_df_copy['Image'][9], cmap = 'gray')\n",
        "for j in range(1, 31, 2):\n",
        "       plt.plot(keyfacial_df_copy.loc[9][j-1], keyfacial_df_copy.loc[9][j], 'rx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyfacial_df_copy = copy.copy(keyfacial_df)"
      ],
      "metadata": {
        "id": "3xaX-LYKdjPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x: np.flip(x, axis = 0))\n",
        "\n",
        "for i in range(len(columns)):\n",
        "  if i%2 == 1:\n",
        "    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x) )"
      ],
      "metadata": {
        "id": "3jXdm57idsB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(keyfacial_df_copy['Image'][0], cmap='gray')\n",
        "for j in range(1, 31, 2):\n",
        "        plt.plot(keyfacial_df_copy.loc[0][j-1], keyfacial_df_copy.loc[0][j], 'rx')"
      ],
      "metadata": {
        "id": "mMjKu48qdvXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the value of images which is present in the 31st column (since index start from 0, we refer to 31st column by 30)\n",
        "img = augmented_df[:,30]\n",
        "\n",
        "# Normalize the images\n",
        "img = img/255.\n",
        "\n",
        "# Create an empty array of shape (x, 96, 96, 1) to feed the model\n",
        "X = np.empty((len(img), 96, 96, 1))\n",
        "\n",
        "# Iterate through the img list and add image values to the empty array after expanding it's dimension from (96, 96) to (96, 96, 1)\n",
        "for i in range(len(img)):\n",
        "  X[i,] = np.expand_dims(img[i], axis = 2)\n",
        "\n",
        "# Convert the array type to float32\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "N75lILD4kgSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the value of x & y coordinates which are to used as target.\n",
        "y = augmented_df[:,:30]\n",
        "y = np.asarray(y).astype(np.float32)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "lIg4fP5nkic3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "KlkeulAnkYXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWFdytt2Mcvl"
      },
      "outputs": [],
      "source": [
        "def res_block(X, filter, stage):\n",
        "\n",
        "  # Convolutional_block\n",
        "  X_copy = X\n",
        "\n",
        "  f1 , f2, f3 = filter\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = MaxPool2D((2,2))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
        "\n",
        "\n",
        "  # Short path\n",
        "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
        "  X_copy = MaxPool2D((2,2))(X_copy)\n",
        "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 1\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 2\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhgJZyKjMcra"
      },
      "outputs": [],
      "source": [
        "input_shape = (96, 96, 1)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Zero-padding\n",
        "X = ZeroPadding2D((3,3))(X_input)\n",
        "\n",
        "# 1 - stage\n",
        "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
        "\n",
        "# 2 - stage\n",
        "X = res_block(X, filter= [64,64,256], stage= 2)\n",
        "\n",
        "# 3 - stage\n",
        "X = res_block(X, filter= [128,128,512], stage= 3)\n",
        "\n",
        "\n",
        "# Average Pooling\n",
        "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
        "\n",
        "# Final layer\n",
        "X = Flatten()(X)\n",
        "X = Dense(4096, activation = 'relu')(X)\n",
        "X = Dropout(0.2)(X)\n",
        "X = Dense(2048, activation = 'relu')(X)\n",
        "X = Dropout(0.1)(X)\n",
        "X = Dense(30, activation = 'relu')(X)\n",
        "\n",
        "\n",
        "model_1_facialKeyPoints = Model( inputs= X_input, outputs = X)\n",
        "model_1_facialKeyPoints.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LfX99-TMcn4"
      },
      "outputs": [],
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = 'adam', metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LwYl-9UMch5"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip uninstall keras\n",
        "!pip install tensorflow\n",
        "!pip install keras==2.12.0\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "model_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = adam , metrics = ['accuracy'])\n",
        "# Check this out for more information on Adam optimizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = \"FacialKeyPoints_weights.hdf5\", verbose = 1, save_best_only = True)"
      ],
      "metadata": {
        "id": "Q_uRgBLMkxzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1_facialKeyPoints.fit(X_train, y_train, batch_size = 32, epochs = 2, validation_split = 0.05, callbacks=[checkpointer])"
      ],
      "metadata": {
        "id": "PvWXm8JIk0oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model architecture to json file for future use\n",
        "\n",
        "model_json = model_1_facialKeyPoints.to_json()\n",
        "with open(\"FacialKeyPoints-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n"
      ],
      "metadata": {
        "id": "GIUnvydulCPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqjDKA12Ncv5HvxkzoHtIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}